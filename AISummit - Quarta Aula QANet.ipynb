{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QANet.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"SsmZmsjn0AMj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":785},"outputId":"5d862068-5d08-4b21-ba65-fd554de1aba8","executionInfo":{"status":"ok","timestamp":1539636564651,"user_tz":180,"elapsed":23231,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["!pip install spacy\n","!pip install bottle\n","!python3 -m spacy download en\n","import tensorflow as tf\n","import random\n","from tqdm import tqdm\n","import spacy\n","import ujson as json\n","from collections import Counter\n","import numpy as np\n","from codecs import open\n","\n","nlp = spacy.blank(\"en\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.12)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.6)\n","Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.28.0)\n","Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.31.2)\n","Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n","Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.10.3)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n","Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n","Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n","Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (2017.4.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n","Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n","Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.4.1)\n","Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n","Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n","Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.26.0)\n","Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.8.24)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n","Collecting bottle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/99/04dc59ced52a8261ee0f965a8968717a255ea84a36013e527944dbf3468c/bottle-0.12.13.tar.gz (70kB)\n","\u001b[K    100% |████████████████████████████████| 71kB 2.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: bottle\n","  Running setup.py bdist_wheel for bottle ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/a0/b4/2a3ee1a32d0506931e558530258de1cc04b628eff1b2f008e0\n","Successfully built bottle\n","Installing collected packages: bottle\n","Successfully installed bottle-0.12.13\n","Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n","\u001b[K    100% |████████████████████████████████| 37.4MB 68.7MB/s \n","\u001b[?25hInstalling collected packages: en-core-web-sm\n","  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n","\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n","\n","\u001b[93m    Linking successful\u001b[0m\n","    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n","\n","    You can now load the model via spacy.load('en')\n","\n"],"name":"stdout"}]},{"metadata":{"id":"mlylD1fCBXJK","colab_type":"text"},"cell_type":"markdown","source":["# Treinamento do Modelo"]},{"metadata":{"id":"K9ixg_lMxKUc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":782},"outputId":"2a605ae4-7a17-4fdb-ff45-d82ecad27dfc","executionInfo":{"status":"ok","timestamp":1539636801502,"user_tz":180,"elapsed":236809,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["!git clone https://github.com/NLPLearn/QANet.git\n","%cd QANet/\n","!bash download.sh"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'QANet'...\n","remote: Enumerating objects: 176, done.\u001b[K\n","remote: Total 176 (delta 0), reused 0 (delta 0), pack-reused 176\u001b[K\n","Receiving objects: 100% (176/176), 357.13 KiB | 498.00 KiB/s, done.\n","Resolving deltas: 100% (103/103), done.\n","/content/QANet\n","--2018-10-15 20:49:30--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.109.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30288272 (29M) [application/json]\n","Saving to: ‘/content/QANet/datasets/squad/train-v1.1.json’\n","\n","/content/QANet/data 100%[===================>]  28.88M   115MB/s    in 0.3s    \n","\n","2018-10-15 20:49:30 (115 MB/s) - ‘/content/QANet/datasets/squad/train-v1.1.json’ saved [30288272/30288272]\n","\n","--2018-10-15 20:49:30--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n","Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.109.153, ...\n","Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4854279 (4.6M) [application/json]\n","Saving to: ‘/content/QANet/datasets/squad/dev-v1.1.json’\n","\n","/content/QANet/data 100%[===================>]   4.63M  --.-KB/s    in 0.1s    \n","\n","2018-10-15 20:49:31 (40.0 MB/s) - ‘/content/QANet/datasets/squad/dev-v1.1.json’ saved [4854279/4854279]\n","\n","--2018-10-15 20:49:31--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n","--2018-10-15 20:49:31--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2176768927 (2.0G) [application/zip]\n","Saving to: ‘/content/QANet/datasets/glove/glove.840B.300d.zip’\n","\n","/content/QANet/data 100%[===================>]   2.03G  11.8MB/s    in 2m 47s  \n","\n","2018-10-15 20:52:18 (12.4 MB/s) - ‘/content/QANet/datasets/glove/glove.840B.300d.zip’ saved [2176768927/2176768927]\n","\n","Archive:  /content/QANet/datasets/glove/glove.840B.300d.zip\n","  inflating: /content/QANet/datasets/glove/glove.840B.300d.txt  \n"],"name":"stdout"}]},{"metadata":{"id":"2sD7Bl-02AV8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"3de73a20-82e4-4688-f8f7-83fd6d76181e","executionInfo":{"status":"ok","timestamp":1539636805850,"user_tz":180,"elapsed":4282,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["config.py  demo.py\tevaluate-v1.1.py  main.py    README.md\t       util.py\n","datasets   Dockerfile\tlayers.py\t  model.py   requirements.txt\n","demo.html  download.sh\tLICENSE\t\t  prepro.py  screenshots\n"],"name":"stdout"}]},{"metadata":{"id":"VBSVmeH2qRdk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"outputId":"ae8dc966-6cae-49f1-b362-c22665c4ed37","executionInfo":{"status":"ok","timestamp":1539637265424,"user_tz":180,"elapsed":459544,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["!python config.py --mode prepro"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Generating train examples...\n","100% 442/442 [01:25<00:00,  5.17it/s]\n","87599 questions in total\n","Generating dev examples...\n","100% 48/48 [00:09<00:00,  4.95it/s]\n","10570 questions in total\n","Generating test examples...\n","100% 48/48 [00:10<00:00,  5.07it/s]\n","10570 questions in total\n","Generating word embedding...\n","100% 2196018/2200000 [04:17<00:00, 8522.73it/s]\n","91594 / 111135 tokens have corresponding word embedding vector\n","Generating char embedding...\n","1425 tokens have corresponding embedding vector\n","Processing train examples...\n","100% 87599/87599 [00:57<00:00, 1521.61it/s]\n","Built 87358 / 87599 instances of features in total\n","Processing dev examples...\n","100% 10570/10570 [00:06<00:00, 1523.05it/s]\n","Built 10482 / 10570 instances of features in total\n","Processing test examples...\n","100% 10570/10570 [00:08<00:00, 1250.90it/s]\n","Built 10570 / 10570 instances of features in total\n","Saving word embedding...\n","Saving char embedding...\n","Saving train eval...\n","Saving dev eval...\n","Saving test eval...\n","Saving dev meta...\n","Saving test meta...\n","Saving word dictionary...\n","Saving char dictionary...\n"],"name":"stdout"}]},{"metadata":{"id":"X7jFP-dYq9T5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":496},"outputId":"0465639d-ab20-453e-c339-9abbae31952f","executionInfo":{"status":"ok","timestamp":1539640577513,"user_tz":180,"elapsed":79138,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["!python config.py --mode train --num_steps 2"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Building model...\n","WARNING:tensorflow:From /content/QANet/layers.py:52: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /content/QANet/model.py:134: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n","Instructions for updating:\n","dim is deprecated, use axis instead\n","WARNING:tensorflow:From /content/QANet/model.py:174: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Total number of trainable parameters: 788673\n","2018-10-15 21:56:06.407004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2018-10-15 21:56:06.407508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","totalMemory: 11.17GiB freeMemory: 11.10GiB\n","2018-10-15 21:56:06.407550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n","2018-10-15 21:56:06.702480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2018-10-15 21:56:06.702550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n","2018-10-15 21:56:06.702575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n","2018-10-15 21:56:06.702902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","0it [00:00, ?it/s]\n"],"name":"stdout"}]},{"metadata":{"id":"uG-lXH_kBTMr","colab_type":"text"},"cell_type":"markdown","source":["# Inferencia no Modelo"]},{"metadata":{"id":"tIYPqJjx1ITm","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","from layers import initializer, regularizer, residual_block, highway, conv, mask_logits, trilinear, total_params, optimized_trilinear_for_attention\n","\n","class Model(object):\n","    def __init__(self, batch, word_mat=None, char_mat=None, trainable=True, opt=True, demo = False, graph = None):\n","        self.config = config\n","        self.demo = demo\n","        self.graph = graph if graph is not None else tf.Graph()\n","        with self.graph.as_default():\n","\n","            self.global_step = tf.get_variable('global_step', shape=[], dtype=tf.int32,\n","                                               initializer=tf.constant_initializer(0), trainable=False)\n","            self.dropout = tf.placeholder_with_default(0.0, (), name=\"dropout\")\n","            self.c = tf.placeholder(tf.int32, [None, 1000],\"context\")\n","            self.q = tf.placeholder(tf.int32, [None, 100],\"question\")\n","            self.ch = tf.placeholder(tf.int32, [None, 1000, 16],\"context_char\")\n","            self.qh = tf.placeholder(tf.int32, [None, 100, 16],\"question_char\")\n","            self.y1 = tf.placeholder(tf.int32, [None, 1000],\"answer_index1\")\n","            self.y2 = tf.placeholder(tf.int32, [None, 1000],\"answer_index2\")\n","\n","            # self.word_unk = tf.get_variable(\"word_unk\", shape = [300], initializer=initializer())\n","            self.word_mat = tf.get_variable(\"word_mat\", initializer=tf.constant(\n","                word_mat, dtype=tf.float32), trainable=False)\n","            self.char_mat = tf.get_variable(\n","                \"char_mat\", initializer=tf.constant(char_mat, dtype=tf.float32))\n","\n","            self.c_mask = tf.cast(self.c, tf.bool)\n","            self.q_mask = tf.cast(self.q, tf.bool)\n","            self.c_len = tf.reduce_sum(tf.cast(self.c_mask, tf.int32), axis=1)\n","            self.q_len = tf.reduce_sum(tf.cast(self.q_mask, tf.int32), axis=1)\n","\n","            if opt:\n","                N, CL = 32 if not self.demo else 1, 16\n","                self.c_maxlen = tf.reduce_max(self.c_len)\n","                self.q_maxlen = tf.reduce_max(self.q_len)\n","                self.c = tf.slice(self.c, [0, 0], [N, self.c_maxlen])\n","                self.q = tf.slice(self.q, [0, 0], [N, self.q_maxlen])\n","                self.c_mask = tf.slice(self.c_mask, [0, 0], [N, self.c_maxlen])\n","                self.q_mask = tf.slice(self.q_mask, [0, 0], [N, self.q_maxlen])\n","                self.ch = tf.slice(self.ch, [0, 0, 0], [N, self.c_maxlen, CL])\n","                self.qh = tf.slice(self.qh, [0, 0, 0], [N, self.q_maxlen, CL])\n","                self.y1 = tf.slice(self.y1, [0, 0], [N, self.c_maxlen])\n","                self.y2 = tf.slice(self.y2, [0, 0], [N, self.c_maxlen])\n","            else:\n","                self.c_maxlen, self.q_maxlen = 400, 50\n","\n","            self.ch_len = tf.reshape(tf.reduce_sum(\n","                tf.cast(tf.cast(self.ch, tf.bool), tf.int32), axis=2), [-1])\n","            self.qh_len = tf.reshape(tf.reduce_sum(\n","                tf.cast(tf.cast(self.qh, tf.bool), tf.int32), axis=2), [-1])\n","\n","            self.forward()\n","            total_params()\n","\n","            if trainable:\n","                self.lr = tf.minimum(0.001, 0.001 / tf.log(999.) * tf.log(tf.cast(self.global_step, tf.float32) + 1))\n","                self.opt = tf.train.AdamOptimizer(learning_rate = self.lr, beta1 = 0.8, beta2 = 0.999, epsilon = 1e-7)\n","                grads = self.opt.compute_gradients(self.loss)\n","                gradients, variables = zip(*grads)\n","                capped_grads, _ = tf.clip_by_global_norm(\n","                    gradients, 5.0)\n","                self.train_op = self.opt.apply_gradients(\n","                    zip(capped_grads, variables), global_step=self.global_step)\n","\n","    def forward(self):\n","        #config = self.config\n","        N, PL, QL, CL, d, dc, nh = 32 if not self.demo else 1, self.c_maxlen, self.q_maxlen, 16, 96, 64, 1\n","\n","        with tf.variable_scope(\"Input_Embedding_Layer\"):\n","            ch_emb = tf.reshape(tf.nn.embedding_lookup(\n","                self.char_mat, self.ch), [N * PL, CL, dc])\n","            qh_emb = tf.reshape(tf.nn.embedding_lookup(\n","                self.char_mat, self.qh), [N * QL, CL, dc])\n","            ch_emb = tf.nn.dropout(ch_emb, 1.0 - 0.5 * self.dropout)\n","            qh_emb = tf.nn.dropout(qh_emb, 1.0 - 0.5 * self.dropout)\n","\n","      # Bidaf style conv-highway encoder\n","            ch_emb = conv(ch_emb, d,\n","                bias = True, activation = tf.nn.relu, kernel_size = 5, name = \"char_conv\", reuse = None)\n","            qh_emb = conv(qh_emb, d,\n","                bias = True, activation = tf.nn.relu, kernel_size = 5, name = \"char_conv\", reuse = True)\n","\n","            ch_emb = tf.reduce_max(ch_emb, axis = 1)\n","            qh_emb = tf.reduce_max(qh_emb, axis = 1)\n","\n","            ch_emb = tf.reshape(ch_emb, [N, PL, ch_emb.shape[-1]])\n","            qh_emb = tf.reshape(qh_emb, [N, QL, ch_emb.shape[-1]])\n","\n","            c_emb = tf.nn.dropout(tf.nn.embedding_lookup(self.word_mat, self.c), 1.0 - self.dropout)\n","            q_emb = tf.nn.dropout(tf.nn.embedding_lookup(self.word_mat, self.q), 1.0 - self.dropout)\n","\n","            c_emb = tf.concat([c_emb, ch_emb], axis=2)\n","            q_emb = tf.concat([q_emb, qh_emb], axis=2)\n","\n","            c_emb = highway(c_emb, size = d, scope = \"highway\", dropout = self.dropout, reuse = None)\n","            q_emb = highway(q_emb, size = d, scope = \"highway\", dropout = self.dropout, reuse = True)\n","\n","        with tf.variable_scope(\"Embedding_Encoder_Layer\"):\n","            c = residual_block(c_emb,\n","                num_blocks = 1,\n","                num_conv_layers = 4,\n","                kernel_size = 7,\n","                mask = self.c_mask,\n","                num_filters = d,\n","                num_heads = nh,\n","                seq_len = self.c_len,\n","                scope = \"Encoder_Residual_Block\",\n","                bias = False,\n","                dropout = self.dropout)\n","            q = residual_block(q_emb,\n","                num_blocks = 1,\n","                num_conv_layers = 4,\n","                kernel_size = 7,\n","                mask = self.q_mask,\n","                num_filters = d,\n","                num_heads = nh,\n","                seq_len = self.q_len,\n","                scope = \"Encoder_Residual_Block\",\n","                reuse = True, # Share the weights between passage and question\n","                bias = False,\n","                dropout = self.dropout)\n","\n","        with tf.variable_scope(\"Context_to_Query_Attention_Layer\"):\n","            # C = tf.tile(tf.expand_dims(c,2),[1,1,self.q_maxlen,1])\n","            # Q = tf.tile(tf.expand_dims(q,1),[1,self.c_maxlen,1,1])\n","            # S = trilinear([C, Q, C*Q], input_keep_prob = 1.0 - self.dropout)\n","            S = optimized_trilinear_for_attention([c, q], self.c_maxlen, self.q_maxlen, input_keep_prob = 1.0 - self.dropout)\n","            mask_q = tf.expand_dims(self.q_mask, 1)\n","            S_ = tf.nn.softmax(mask_logits(S, mask = mask_q))\n","            mask_c = tf.expand_dims(self.c_mask, 2)\n","            S_T = tf.transpose(tf.nn.softmax(mask_logits(S, mask = mask_c), dim = 1),(0,2,1))\n","            self.c2q = tf.matmul(S_, q)\n","            self.q2c = tf.matmul(tf.matmul(S_, S_T), c)\n","            attention_outputs = [c, self.c2q, c * self.c2q, c * self.q2c]\n","\n","        with tf.variable_scope(\"Model_Encoder_Layer\"):\n","            inputs = tf.concat(attention_outputs, axis = -1)\n","            self.enc = [conv(inputs, d, name = \"input_projection\")]\n","            for i in range(3):\n","                if i % 2 == 0: # dropout every 2 blocks\n","                    self.enc[i] = tf.nn.dropout(self.enc[i], 1.0 - self.dropout)\n","                self.enc.append(\n","                    residual_block(self.enc[i],\n","                        num_blocks = 7,\n","                        num_conv_layers = 2,\n","                        kernel_size = 5,\n","                        mask = self.c_mask,\n","                        num_filters = d,\n","                        num_heads = nh,\n","                        seq_len = self.c_len,\n","                        scope = \"Model_Encoder\",\n","                        bias = False,\n","                        reuse = True if i > 0 else None,\n","                        dropout = self.dropout)\n","                    )\n","\n","        with tf.variable_scope(\"Output_Layer\"):\n","            start_logits = tf.squeeze(conv(tf.concat([self.enc[1], self.enc[2]],axis = -1),1, bias = False, name = \"start_pointer\"),-1)\n","            end_logits = tf.squeeze(conv(tf.concat([self.enc[1], self.enc[3]],axis = -1),1, bias = False, name = \"end_pointer\"), -1)\n","            self.logits = [mask_logits(start_logits, mask = self.c_mask),\n","                           mask_logits(end_logits, mask = self.c_mask)]\n","\n","            logits1, logits2 = [l for l in self.logits]\n","\n","            outer = tf.matmul(tf.expand_dims(tf.nn.softmax(logits1), axis=2),\n","                              tf.expand_dims(tf.nn.softmax(logits2), axis=1))\n","            outer = tf.matrix_band_part(outer, 0, 30)\n","            self.yp1 = tf.argmax(tf.reduce_max(outer, axis=2), axis=1)\n","            self.yp2 = tf.argmax(tf.reduce_max(outer, axis=1), axis=1)\n","            losses = tf.nn.softmax_cross_entropy_with_logits(\n","                logits=logits1, labels=self.y1)\n","            losses2 = tf.nn.softmax_cross_entropy_with_logits(\n","                logits=logits2, labels=self.y2)\n","            self.loss = tf.reduce_mean(losses + losses2)\n","\n","        if 3e-7 is not None:\n","            variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n","            l2_loss = tf.contrib.layers.apply_regularization(regularizer, variables)\n","            self.loss += l2_loss\n","\n","        if 0.9999 is not None:\n","            self.var_ema = tf.train.ExponentialMovingAverage(0.9999)\n","            ema_op = self.var_ema.apply(tf.trainable_variables())\n","            with tf.control_dependencies([ema_op]):\n","                self.loss = tf.identity(self.loss)\n","\n","                self.assign_vars = []\n","                for var in tf.global_variables():\n","                    v = self.var_ema.average(var)\n","                    if v:\n","                        self.assign_vars.append(tf.assign(var,v))\n","\n","    def get_loss(self):\n","        return self.loss\n","\n","    def get_global_step(self):\n","        return self.global_step"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RbdQBfysy5Nt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ad97be66-7e62-4f87-aa1a-6b3cc6743106","executionInfo":{"status":"ok","timestamp":1539643133587,"user_tz":180,"elapsed":22960,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["with open(word_emb_file, \"r\") as fh:\n","    word_mat = np.array(json.load(fh), dtype=np.float32)\n","with open(char_emb_file, \"r\") as fh:\n","    char_mat = np.array(json.load(fh), dtype=np.float32)\n","with open(test_meta, \"r\") as fh:\n","    meta = json.load(fh)\n","\n","model = Model(config, None, word_mat, char_mat, trainable=False, demo = True)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Total number of trainable parameters: 788673\n"],"name":"stdout"}]},{"metadata":{"id":"pxAX9uFW4atd","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_to_features(config, data, word2idx_dict, char2idx_dict):\n","\n","    example = {}\n","    context, question = data\n","    context = context.replace(\"''\", '\" ').replace(\"``\", '\" ')\n","    question = question.replace(\"''\", '\" ').replace(\"``\", '\" ')\n","    example['context_tokens'] = word_tokenize(context)\n","    example['ques_tokens'] = word_tokenize(question)\n","    example['context_chars'] = [list(token) for token in example['context_tokens']]\n","    example['ques_chars'] = [list(token) for token in example['ques_tokens']]\n","\n","    para_limit = 1000\n","    ques_limit = 100\n","    ans_limit = 15\n","    char_limit = 16\n","\n","    def filter_func(example):\n","        return len(example[\"context_tokens\"]) > para_limit or \\\n","               len(example[\"ques_tokens\"]) > ques_limit\n","\n","    if filter_func(example):\n","        raise ValueError(\"Context/Questions lengths are over the limit\")\n","\n","    context_idxs = np.zeros([para_limit], dtype=np.int32)\n","    context_char_idxs = np.zeros([para_limit, char_limit], dtype=np.int32)\n","    ques_idxs = np.zeros([ques_limit], dtype=np.int32)\n","    ques_char_idxs = np.zeros([ques_limit, char_limit], dtype=np.int32)\n","    y1 = np.zeros([para_limit], dtype=np.float32)\n","    y2 = np.zeros([para_limit], dtype=np.float32)\n","\n","    def _get_word(word):\n","        for each in (word, word.lower(), word.capitalize(), word.upper()):\n","            if each in word2idx_dict:\n","                return word2idx_dict[each]\n","        return 1\n","\n","    def _get_char(char):\n","        if char in char2idx_dict:\n","            return char2idx_dict[char]\n","        return 1\n","\n","    for i, token in enumerate(example[\"context_tokens\"]):\n","        context_idxs[i] = _get_word(token)\n","\n","    for i, token in enumerate(example[\"ques_tokens\"]):\n","        ques_idxs[i] = _get_word(token)\n","\n","    for i, token in enumerate(example[\"context_chars\"]):\n","        for j, char in enumerate(token):\n","            if j == char_limit:\n","                break\n","            context_char_idxs[i, j] = _get_char(char)\n","\n","    for i, token in enumerate(example[\"ques_chars\"]):\n","        for j, char in enumerate(token):\n","            if j == char_limit:\n","                break\n","            ques_char_idxs[i, j] = _get_char(char)\n","    \n","    return context_idxs, context_char_idxs, ques_idxs, ques_char_idxs\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7lFvh5QM_UtL","colab_type":"code","colab":{}},"cell_type":"code","source":["def word_tokenize(sent):\n","    doc = nlp(sent)\n","    return [token.text for token in doc]\n","  \n","def del_all_flags(FLAGS):\n","    flags_dict = FLAGS._flags()    \n","    keys_list = [keys for keys in flags_dict]    \n","    for keys in keys_list:\n","        FLAGS.__delattr__(keys)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JlYbKbRCu2F-","colab_type":"code","colab":{}},"cell_type":"code","source":["def ParseModel(query):\n","  \n","  target_dir = \"data/\"\n","  train_dir = \"train/\"\n","  word_dictionary = target_dir + \"word_dictionary.json\"\n","  char_dictionary = target_dir + \"char_dictionary.json\"\n","  word_emb_file = target_dir   + \"word_emb.json\"\n","  char_emb_file = target_dir   + \"char_emb.json\"\n","  test_meta = target_dir       + \"test_meta.json\"\n","\n","  dir_name = train_dir + \"FRC\"\n","  save_dir = dir_name          + \"model\"\n","\n","  del_all_flags(tf.flags.FLAGS)\n","\n","  flags = tf.flags\n","\n","  flags.DEFINE_string(\"mode\", \"train\", \"Running mode train/debug/test\")\n","  tf.app.flags.DEFINE_string('f', '', 'kernel')\n","\n","\n","\n","  with open(word_dictionary, \"r\") as fh:\n","        word_dictionary = json.load(fh)\n","        with open(char_dictionary, \"r\") as fh:\n","            char_dictionary = json.load(fh)\n","\n","        sess_config = tf.ConfigProto(allow_soft_placement=True)\n","        sess_config.gpu_options.allow_growth = True\n","\n","        with model.graph.as_default():\n","\n","            with tf.Session(config=sess_config) as sess:\n","                sess.run(tf.global_variables_initializer())\n","                saver = tf.train.Saver()\n","                saver.restore(sess, tf.train.latest_checkpoint(\"./train/FRC/model/\"))\n","                if 0.9999 < 1.0:\n","                    sess.run(model.assign_vars)\n","\n","\n","                if query:\n","                    context = word_tokenize(query[0].replace(\"''\", '\" ').replace(\"``\", '\" '))\n","                    c,ch,q,qh = convert_to_features(config, query, word_dictionary, char_dictionary)\n","                    fd = {'context:0': [c],\n","                          'question:0': [q],\n","                          'context_char:0': [ch],\n","                          'question_char:0': [qh]}\n","                    yp1,yp2 = sess.run([model.yp1, model.yp2], feed_dict = fd)\n","                    yp2[0] += 1\n","                    response = \" \".join(context[yp1[0]:yp2[0]])\n","                    print(\"Resposta: \", response)\n","                    query = []\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1wM7a134AMYg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"39824f95-221b-4ff3-ea4a-381d01f3ebb4","executionInfo":{"status":"ok","timestamp":1539645438199,"user_tz":180,"elapsed":13372,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["\n","passage = \"Machine learning is a field of artificial intelligence that uses statistical techniques to give computer systems the ability to learn from data, without being explicitly programmed. The name machine learning was coined in 1959 by Arthur Samuel.\"\n","query   = \"when arthur samuel culminated the term?\"\n","\n","ParseModel([passage, query])"],"execution_count":123,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./train/FRC/model/model_3000.ckpt\n","Resposta:  1959 by Arthur Samuel\n"],"name":"stdout"}]}]}