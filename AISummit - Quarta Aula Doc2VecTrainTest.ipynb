{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AISummit - Terceira Aula Doc2VecTrainTest.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/deeplearningbrasil/summerschool2018/blob/master/quinta/tarde/word_embeddings/doc2vec_train.ipynb","timestamp":1539625983197}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"deletable":true,"editable":true,"id":"OSpbvEA43AWA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"8cf61587-d85b-4769-f8d4-59653ba5bcb2","executionInfo":{"status":"ok","timestamp":1539628246019,"user_tz":180,"elapsed":5896,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["!pip3 install nltk googledrivedownloader gensim\n","import gensim.models as g\n","import logging\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.3)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.23)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n","Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.23 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.23)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.23->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.23->boto3->smart-open>=1.2.1->gensim) (0.14)\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"_3B-02o53AWF","colab_type":"code","colab":{}},"cell_type":"code","source":["from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","gdd.download_file_from_google_drive(file_id='1shL8-LgL4HaaWSYCb2K09PlyomGFREEB', dest_path='./sinopses.txt', unzip=False) # pesa 3GB"],"execution_count":0,"outputs":[]},{"metadata":{"deletable":true,"editable":true,"id":"UJ3h2cRa3AWK","colab_type":"text"},"cell_type":"markdown","source":["Aqui definimos as varíaveis que serão usadas como parâmetro no nosso treinamento."]},{"metadata":{"deletable":true,"editable":true,"id":"Z9l39w5d3AWL","colab_type":"code","colab":{}},"cell_type":"code","source":["#doc2vec parameters\n","vector_size = 300\n","window_size = 15\n","min_count = 1\n","sampling_threshold = 1e-5\n","negative_size = 5\n","train_epoch = 2\n","dm = 1 #0 = dbow; 1 = dmpv\n","worker_count = 2"],"execution_count":0,"outputs":[]},{"metadata":{"deletable":true,"editable":true,"id":"7_234nms3AWO","colab_type":"text"},"cell_type":"markdown","source":["O córpus que utilizaremos é um de sinopses de filmes com aproximadamente 10496 sinopses."]},{"metadata":{"deletable":true,"editable":true,"id":"YfacLtiZ3AWP","colab_type":"code","colab":{}},"cell_type":"code","source":["#input corpus\n","train_corpus = \"sinopses.txt\" #train_docs"],"execution_count":0,"outputs":[]},{"metadata":{"deletable":true,"editable":true,"id":"HW0k35bZ3AWS","colab_type":"text"},"cell_type":"markdown","source":["Faremos a remoção de _stopwords_ para eliminar ruído dos dados."]},{"metadata":{"deletable":true,"editable":true,"id":"JUvx5A5q3AWS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"617f2ad7-86f5-474e-a85f-c586e3ce3d23","executionInfo":{"status":"ok","timestamp":1539628253066,"user_tz":180,"elapsed":697,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["#stopwords\n","pt_stop = stopwords.words('portuguese')\n","pt_stop.extend(['para','que'])\n","print(pt_stop)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam', 'para', 'que']\n"],"name":"stdout"}]},{"metadata":{"deletable":true,"editable":true,"id":"-zQsGR7h3AWV","colab_type":"text"},"cell_type":"markdown","source":["Esse método faz a leitura do córpus enquanto remove as _stopwords_.\n","\n","* **TaggedDocument**: Adiciona uma _label_ para cada documento (sinopse). Neste caso, estamos adicionando o contador como _label_. Normalmente se usa um id inteiro único."]},{"metadata":{"deletable":true,"editable":true,"id":"hqC-k3Vp3AWX","colab_type":"code","colab":{}},"cell_type":"code","source":["def read_corpus(fname, tokens_only=False): \n","    with open(fname) as f: #\n","        read_data = f.readlines()\n","        for i, line in enumerate(read_data):\n","            t_corpus = line.split(\" | \")\n","            if(len(t_corpus)==2):\n","                #removing stopwords\n","                words = t_corpus[1].split()\n","                filtered_words = [word for word in words if word not in pt_stop]\n","                yield g.doc2vec.TaggedDocument(filtered_words, [i])"],"execution_count":0,"outputs":[]},{"metadata":{"deletable":true,"editable":true,"id":"VYl82ury3AWa","colab_type":"code","colab":{}},"cell_type":"code","source":["train_docs = list(read_corpus(train_corpus))"],"execution_count":0,"outputs":[]},{"metadata":{"deletable":true,"editable":true,"id":"pbFUrj2M3AWd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"abffcc26-42b2-40b8-e245-a70a3ed92261","executionInfo":{"status":"ok","timestamp":1539628261274,"user_tz":180,"elapsed":901,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["train_docs[:5]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TaggedDocument(words=['As', 'coisas', 'mal', 'Inteligência', 'Britânica,', 'pois', 'Smersh', 'começara', 'sabotar', 'estabilidade', 'global:', 'nada', 'menos', 'onze', 'agentes', 'abatidos', 'e,', 'piorar', 'coisas,', 'maior', 'agente', 'secreto,', '007,', 'desfrutando', 'aposentadoria.', 'Sir', 'James', 'Bond,', 'primeiro', '007,', 'é', 'convencido', 'alguns', 'chefes', 'agências', 'espionagem', 'combater', 'inimigo', 'comum.', 'Essa', 'versão', '\"Cassino', 'Royale\"', 'é', 'versão', 'oficial', 'filmes', '007,', 'pois', 'rodado', 'outra', 'equipe,', 'estúdios,', 'padrões', 'contratos.', 'É', 'produção', 'anglo-americana', '1967,', 'gênero', 'comédia', 'espionagem.'], tags=[0]),\n"," TaggedDocument(words=['A', 'ação', 'é', 'eletrizante', 'ininterrupta,', 'pois', 'agente', '007', '(Sean', 'Connery)', 'vai', 'além', 'dever', 'ofício', 'profundezas', 'oceano', 'encontrar', 'perigoso', 'criminoso', 'ameaçando', 'milhões', 'pessoas', 'através', 'chantagem', 'destruir', 'mundo', 'meio', 'holocausto', 'nuclear.'], tags=[1]),\n"," TaggedDocument(words=['Com', 'queda', 'Cortina', 'Ferro', 'final', 'Guerra', 'Fria,', 'modo', 'obter', 'poder', 'deu', 'mundo', 'nova', 'ordem,', 'envolvem', 'esquemas', 'perigosos', 'visam', 'apenas', 'lucro.', 'Neste', 'contexto,', 'James', 'Bond', '(Pierce', 'Brosnan)', 'conhece', 'Mônaco', 'Xenia', 'Onatopp', '(Famke', 'Janssen),', 'mulher', 'extremamente', 'bela', 'perigosamente', 'mortal,', 'pertence', 'Máfia', 'russa.', 'Bond', 'tenta', 'encontrar', 'Goldeneye,', 'arma', 'secreta', 'espacial', 'destrói', 'tudo', 'circuito', 'eletrônico', 'que,', 'caso', 'caia', 'mãos', 'erradas', 'dará', 'donos', 'poder', 'derrubar', 'governos.', 'Para', 'impedir', 'catástrofe', 'mundial,', 'James', 'une', 'Natalya', 'Simonova', '(Izabella', 'Scorupco),', 'programadora', 'computadores.'], tags=[2]),\n"," TaggedDocument(words=['Desde', 'explosiva', 'abertura', 'fuga', 'último', 'minuto', 'jatinho', 'pessoal', 'Presidente,', 'terceira', 'aventura', 'James', 'Bond', 'é', 'ágil', 'excitante!', 'Sean', 'Connery', 'encarna', 'novamente', 'Agente', '007', 'enfrentar', 'vilão', 'maníaco', 'determinado', 'destruir', 'todo', 'ouro', 'Fort', 'Knox', 'acabar', 'economia', 'mundial!'], tags=[3]),\n"," TaggedDocument(words=['No', 'filme', 'lançou', 'saga', 'James', 'Bond,', 'Agente', '007', '(Sean', 'Connery),', 'enfrentar', 'misterioso', 'Dr.', 'No,', 'cientista', 'gênio', 'determinado', 'destruir', 'programa', 'espacial', 'norte-americano.', 'Correndo', 'contra', 'contagem', 'regressiva', 'desastre,', 'Bond', 'precisa', 'viajar', 'Jamaica,', 'onde', 'encontra', 'linda', 'Honey', 'Ryder', '(Ursula', 'Andress)', 'confronta', 'vilão', 'megalomaníaco', 'ilha', 'fortaleza.'], tags=[4])]"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"deletable":true,"editable":true,"id":"gSb1u46A3AWh","colab_type":"code","colab":{}},"cell_type":"code","source":["logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"],"execution_count":0,"outputs":[]},{"metadata":{"deletable":true,"editable":true,"id":"40WeSWWS3AWl","colab_type":"text"},"cell_type":"markdown","source":["### Parâmetros\n","\n","Na próxima célula de código, definimos os seguintes parâmetros:\n","* **size**: dimensionalidade dos vetores.\n","\n","* **window**: é a quantidade de palavras anteriores e posteriores à palavra alvo.\n","\n","* **min_count**: ignore as palavras com frequência total inferior a **min_count**.\n","\n","* **sample**: limiar para configurar quais palavras de maior frequência são aleatoriamente reduzidas; O padrão é 1e-3, o intervalo útil é (0, 1e-5).\n","\n","* **workers**: parâmetro que indica quantos cores da máquina serão utilizados para o treinamento.\n","\n","* **hs**: se 1, softmax hierárquico será usado para o treinamento do modelo. Se definido como 0 (padrão), e existir amostragem negativa, esse recurso será utilizado.\n","\n","* **dm**: define o algoritmo de treinamento. Por padrão, o DBOW é usado (dm = 0). O outro é o DMPV (dm = 1).\n","\n","* **negative**: se > 0, será utilizada amostragem negativa. O valor indica quantas \"palavras de ruído\" devem ser consideradas (normalmente entre 5 a 20). Se **negative** configurado para 0, não é utilizada a amostragem negativa.\n","\n","* **dbow_words**: se 1, skip-gram é usado para gerar os vetores de palavras simultaneamente com DBOW; O padrão é 0. Essa funcionalidade aumenta o conjunto de dados ao adicionar os vetores de palavras junto aos de documento. o treinamento ficará mais lento.\n","\n","* **dm_concat**: se 1, usa a concatenação de vetores de contexto em vez da soma/média; O padrão é 0 (desativado).\n","\n","* **iter**: número de iterações (épocas) sobre o córpus. O padrão é 5.\n","\n","\n","\n"]},{"metadata":{"deletable":true,"editable":true,"id":"zusRHwXS3AWm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"870fcedf-43f9-48a6-b543-ee61a4035e7b","executionInfo":{"status":"ok","timestamp":1539628303051,"user_tz":180,"elapsed":677,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["model = g.doc2vec.Doc2Vec(size=vector_size, window=window_size, min_count=min_count, sample=sampling_threshold, workers=worker_count, hs=0, dm=dm, negative=negative_size, dbow_words=1, dm_concat=1, iter=train_epoch)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:566: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n","  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n","/usr/local/lib/python3.6/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n","  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n","2018-10-15 18:31:42,562 : INFO : using concatenative 9300-dimensional layer1\n"],"name":"stderr"}]},{"metadata":{"deletable":true,"editable":true,"id":"X6u1vzCY3AWo","colab_type":"text"},"cell_type":"markdown","source":["* **build_vocab**: Método que constrói um dicionário de palavras distintas presentes no córpus."]},{"metadata":{"deletable":true,"editable":true,"id":"PfqapaN63AWp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"05ec44d1-2ac8-4caa-af07-df88d28d9ec5","executionInfo":{"status":"ok","timestamp":1539628308712,"user_tz":180,"elapsed":5245,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["model.build_vocab(train_docs)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2018-10-15 18:31:43,769 : INFO : collecting all words and their counts\n","2018-10-15 18:31:43,771 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n","2018-10-15 18:31:43,914 : INFO : collected 62995 word types and 7771 unique tags from a corpus of 7529 examples and 296335 words\n","2018-10-15 18:31:43,915 : INFO : Loading a fresh vocabulary\n","2018-10-15 18:31:44,174 : INFO : effective_min_count=1 retains 62995 unique words (100% of original 62995, drops 0)\n","2018-10-15 18:31:44,175 : INFO : effective_min_count=1 leaves 296335 word corpus (100% of original 296335, drops 0)\n","2018-10-15 18:31:44,380 : INFO : deleting the raw counts dictionary of 62995 items\n","2018-10-15 18:31:44,383 : INFO : sample=1e-05 downsamples 5677 most-common words\n","2018-10-15 18:31:44,384 : INFO : downsampling leaves estimated 164586 word corpus (55.5% of prior 296335)\n","2018-10-15 18:31:44,683 : INFO : estimated required memory for 62995 words and 300 dimensions: 2459830700 bytes\n","2018-10-15 18:31:44,685 : INFO : resetting layer weights\n"],"name":"stderr"}]},{"metadata":{"deletable":true,"editable":true,"id":"xj1wm49j3AWt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"b7e58339-9fe4-4f41-da8d-811e46b33e71","executionInfo":{"status":"ok","timestamp":1539628329263,"user_tz":180,"elapsed":20510,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["# Aqui ocorre o treinamento do nosso modelo.\n","%time model.train(train_docs, total_examples=model.corpus_count, epochs=model.iter)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n","  \"\"\"Entry point for launching an IPython kernel.\n","2018-10-15 18:31:49,126 : INFO : training model with 1 workers on 62996 vocabulary and 9300 features, using sg=0 hs=0 sample=1e-05 negative=5 window=15\n","2018-10-15 18:31:50,300 : INFO : EPOCH 1 - PROGRESS: at 10.09% examples, 15004 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:51,466 : INFO : EPOCH 1 - PROGRESS: at 20.11% examples, 14898 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:52,642 : INFO : EPOCH 1 - PROGRESS: at 30.32% examples, 14814 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:53,985 : INFO : EPOCH 1 - PROGRESS: at 44.34% examples, 15482 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:55,265 : INFO : EPOCH 1 - PROGRESS: at 58.67% examples, 16041 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:56,551 : INFO : EPOCH 1 - PROGRESS: at 71.64% examples, 16397 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:57,839 : INFO : EPOCH 1 - PROGRESS: at 84.35% examples, 16671 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:59,120 : INFO : EPOCH 1 - PROGRESS: at 97.70% examples, 16877 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:31:59,350 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2018-10-15 18:31:59,351 : INFO : EPOCH - 1 : training on 296335 raw words (172380 effective words) took 10.2s, 16902 effective words/s\n","2018-10-15 18:32:00,591 : INFO : EPOCH 2 - PROGRESS: at 13.30% examples, 18601 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:32:01,842 : INFO : EPOCH 2 - PROGRESS: at 26.98% examples, 18502 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:32:03,101 : INFO : EPOCH 2 - PROGRESS: at 40.63% examples, 18432 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:32:04,370 : INFO : EPOCH 2 - PROGRESS: at 55.17% examples, 18410 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:32:05,643 : INFO : EPOCH 2 - PROGRESS: at 68.47% examples, 18355 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:32:06,942 : INFO : EPOCH 2 - PROGRESS: at 81.21% examples, 18295 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:32:08,232 : INFO : EPOCH 2 - PROGRESS: at 94.43% examples, 18296 words/s, in_qsize 1, out_qsize 0\n","2018-10-15 18:32:08,785 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2018-10-15 18:32:08,786 : INFO : EPOCH - 2 : training on 296335 raw words (172181 effective words) took 9.4s, 18268 effective words/s\n","2018-10-15 18:32:08,789 : INFO : training on a 592670 raw words (344561 effective words) took 19.7s, 17531 effective words/s\n"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 19.5 s, sys: 25.2 ms, total: 19.5 s\n","Wall time: 19.7 s\n"],"name":"stdout"}]},{"metadata":{"deletable":true,"editable":true,"id":"BMSeK65N3AWz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"2e5535b9-7d8e-4660-d030-71879d026c7f","executionInfo":{"status":"ok","timestamp":1539628414681,"user_tz":180,"elapsed":71177,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["# Salva o modelo no disco\n","model.save(\"doc2vecmodel.bin\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["2018-10-15 18:32:23,630 : INFO : saving Doc2Vec object under doc2vecmodel.bin, separately None\n","2018-10-15 18:32:23,635 : INFO : storing np array 'syn1neg' to doc2vecmodel.bin.trainables.syn1neg.npy\n","2018-10-15 18:33:33,381 : INFO : storing np array 'vectors' to doc2vecmodel.bin.wv.vectors.npy\n","2018-10-15 18:33:34,223 : INFO : saved doc2vecmodel.bin\n"],"name":"stderr"}]},{"metadata":{"deletable":true,"editable":true,"id":"XF2ReB1p3AW5","colab_type":"code","colab":{}},"cell_type":"code","source":["import codecs\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-Gt6sGfU4jBL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"fb7a6971-87e5-4e79-99ac-1118c32afda2","executionInfo":{"status":"ok","timestamp":1539628528340,"user_tz":180,"elapsed":111964,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["# Aqui faremos o carregamento do modelo treinado.\n","\n","m = g.Doc2Vec.load(\"doc2vecmodel.bin\")\n","print(m.docvecs.count)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["2018-10-15 18:33:36,621 : INFO : loading Doc2Vec object from doc2vecmodel.bin\n","2018-10-15 18:33:36,975 : INFO : loading vocabulary recursively from doc2vecmodel.bin.vocabulary.* with mmap=None\n","2018-10-15 18:33:36,977 : INFO : loading trainables recursively from doc2vecmodel.bin.trainables.* with mmap=None\n","2018-10-15 18:33:36,978 : INFO : loading syn1neg from doc2vecmodel.bin.trainables.syn1neg.npy with mmap=None\n","2018-10-15 18:35:24,432 : INFO : loading wv recursively from doc2vecmodel.bin.wv.* with mmap=None\n","2018-10-15 18:35:24,438 : INFO : loading vectors from doc2vecmodel.bin.wv.vectors.npy with mmap=None\n","2018-10-15 18:35:27,792 : INFO : loading docvecs recursively from doc2vecmodel.bin.docvecs.* with mmap=None\n","2018-10-15 18:35:27,793 : INFO : loaded doc2vecmodel.bin\n"],"name":"stderr"},{"output_type":"stream","text":["7771\n"],"name":"stdout"}]},{"metadata":{"id":"mld8vhmn4lc1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":83983,"output_embedded_package_id":"1O_QOTdir5TmcyVQT8DTIa5qAsDU4brad"},"outputId":"bf9d8c1b-1341-4756-e5c3-4876a08f1342","executionInfo":{"status":"ok","timestamp":1539628532403,"user_tz":180,"elapsed":4029,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["# Tokenizaremos cada sinopse e adicionaremos as palavras em um vetor que será usado para a inferência.\n","alldocs = []\n","cont = 0\n","with open(train_corpus) as alldata: #, encoding='utf-8'\n","    for line_no, line in enumerate(alldata):\n","        words = g.utils.to_unicode(line).split()\n","        alldocs.append(words)\n","        print(words)\n","        cont+=1"],"execution_count":17},{"metadata":{"id":"EWiOqj8x5cz_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"5dfda833-2e47-41b7-a491-9264eed8ec0d","executionInfo":{"status":"ok","timestamp":1539628574498,"user_tz":180,"elapsed":618,"user":{"displayName":"Marco Oliveira","photoUrl":"","userId":"08693184838751300851"}}},"cell_type":"code","source":["doc_id = np.random.randint(m.docvecs.count)  # pick random doc, re-run cell for more examples\n","#print(m.docvecs.count)\n","sims = m.docvecs.most_similar(doc_id, topn=m.docvecs.count)  # get *all* similar documents m.docvecs.count\n","print(u'TARGET (%d): %s\\n' % (doc_id, ' '.join(alldocs[doc_id])))\n","print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % m)\n","for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n","    print(u'%s %s: %s\\n' % (label, sims[index], ' '.join(alldocs[sims[index][0]])))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["TARGET (4311): Mrs. Soffel - Um Amor Proibido(1984) | Pittsburgh, 1901. Peter Soffel (Edward Herrmann) é o diretor de uma prisão de segurança máxima e Kate Soffel (Diane Keaton), sua esposa, apesar de ter uma saúde frágil freqüentemente lê a Bíblia em voz alta para os internos. Durante sua ronda habitual Kate fica sabendo dos Irmãos Biddle, Ed (Mel Gibson) e Jack (Matthew Modine), que foram condenados à morte por assassinato e roubo. Ed tem boa aparência, é inteligente e charmoso, fazendo Kate ficar impressionada. Gradativamente, ela se apaixona por Ed e ajuda os dois irmãos a escaparem da prisão, fugindo com eles.\n","\n","SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/c,d300,n5,w15,s1e-05):\n","\n","MOST (4487, 0.21790188550949097): Noivas | Liv (Kate Hudson) e Emma (Anne Hathaway) são grandes amigas e planejaram seus respectivos casamentos nos mínimos detalhes desde crianças, quando brincavam juntas cantando \"Lá vem a noiva\" em seus sótãos. Sempre souberam, sem sombra de dúvida, que se casariam no local dos casamentos mais badalados de Nova York: o Hotel Plaza. Agora, aos 26 anos, ambas estão prestes a casar; prestes a realizar seu sonho, vivendo felizes para sempre. Ou talvez não... Um erro na marcação da data, fazendo coincidir os casamentos, joga essas mulheres sensatas, racionais e respeitáveis uma contra a outra, num conflito que vai abalar a amizade.\n","\n","MEDIAN (5738, -0.0005248915404081345): Pequenas Histórias | Na varanda de uma fazenda uma senhora (Marieta Severo) conta histórias ao mesmo tempo em que corta e costura retalhos de pano, de forma a gerar uma toalha.\n","\n","LEAST (7244, -0.19866937398910522): Uma Incrível Aventura | Um garoto pobre e determinado, que adora futebol, acredita no talento de um amigo para o esporte e o convence a participar da Copa do Mundo, na África do Sul. Sem dinheiro e a milhares de quilômetros daquele país, eles partem, sem olhar pra trás, em busca desse objetivo. Ao longo do caminho, juntam-se a eles novos companheiros que passam a acreditar nesse mesmo sonho. Nada os fará desistir. Nessa longa caminhada, eles descobrem o verdadeiro significado da amizade, lealdade e perseverança.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]}]}